---
title: "ESM232 Assignment 8: Evaluating Models"
author: "Pat Byrne, Kat Leigh, Ruoyu Wang"
date: "5/20/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,
                      message = FALSE,
                      warning = FALSE)
library(tidyverse)
library(purrr)
library(lubridate)
```

### 1. Code metric as a function

Our metric: estimated minimal and maximal flow must both have a Pearsonâ€™s Correlation Coefficient greater than 0.6, but the closer to 1, the better.

```{r func}
# call out function "perform_metric"
source('kat_pat_ruoyu_perform_metric.R')
```

### 2. Apply to the streamflow data provided in sagerm.txt (multiple model results)

```{r data}
# read observation data
sager <- read.table("sager.txt", header=T)

# add date from the existing columns of day, month, year
sager <- sager %>% 
  mutate(date=make_date(year=year, month=month, day=day))

# read in simulation outputs
msage = read.table("sagerm.txt", header=T)

# combine the simulation outputs with date and actual observation data in sager.txt
msage$date = sager$date
msage$month = sager$month
msage$year = sager$year
msage$day = sager$day
msage$wy = sager$wy
msage$obs = sager$obs
```

```{r clean.data}
# turn all the columns of different outputs into a single column identified by "run"
msagel = msage %>% 
  gather(key="run",
         value="streamflow", 
         -date, -month, -day, 
         -year, -wy, -obs)
```


```{r apply}
# apply the perform_metric function to our data, the grouping variable is year
res = msage %>% 
  select(-date, -month, -day, -year, -wy, -obs) %>%
  map_dfr(~perform_metric(m=.x, 
                          o=msage$obs, 
                          month = msage$month, 
                          day = msage$day,
                          year=msage$year, 
                          wy=msage$wy,
                          grouping=msage$year))


# crate an ID that tracks each model output
simnames = names(msage %>% 
  select(-date, -month, -day,-year,-wy, -obs))

results = cbind.data.frame(simnames=simnames, res)

# Make results long format
resultsl = results %>% 
  gather(key="metric",value="value", -simnames) 
```

### 3.  Find the simulation that gives the best performance 

```{r best}
# find the best model run (highest average correlation, and both coefficients are larger than 0.6)

bestdf <- results %>% 
  filter(annual_min_cor > 0.6,
         annual_max_cor > 0.6) %>%  
  mutate(
    ave_cor = (annual_min_cor+annual_max_cor)/2
  ) %>% 
  arrange(-ave_cor)

print(as.character(bestdf$simnames[1]))
```


### 4. Create a boxplot of our metric applied to sagerm.txt

```{r boxplot, fig.width=7, fig.height=4}
metric_label <- c(annual_max_cor = "Correlations for Annual Max Flow",
                  annual_min_cor = "Correlations for Annual Min Flow")

# graph range of performance measures
ggplot(resultsl, aes(metric, value))+
  geom_boxplot()+
  labs(x='Performance Metric Correlated Variable',
       y='Pearson Correlation Coefficient',
       title = 'Model Performance: Correlation between Simulated and Observed Values')+
  facet_wrap(~metric, scales="free",
             labeller = as_labeller(metric_label))+
  theme_bw()+
  theme(axis.text.x = element_blank())

# ggsave("kat_pat_ruoyu_boxplot.png", dpi = 400, width=7, height=4)
```
Do this for all possible time periods with a single function

```{r}
data_F <- msage
groupingz <- list('date', 'month', 'day', 'year', 'wy')

wrapper <- function(data_F, groupingz){

# apply the perform_metric function to our data
  
res = data_F %>% 
  select(-date, -month, -day, -year, -wy, -obs) %>%
  map_dfr(~perform_metric(m=.x, 
                          o=data_F$obs, 
                          month = data_F$month, 
                          day = data_F$day,
                          year=data_F$year, 
                          wy=data_F$wy,
                          grouping= eval(parse(text = paste('data_F$',groupingz[i], sep = '')))))

# create an ID that tracks each model output
simnames = names(data_F %>% 
  select(-date, -month, -day,-year,-wy, -obs))

results = cbind.data.frame(simnames=simnames, res)

# Make results long format
resultsl = results %>% 
  gather(key="metric",value="value", -simnames) 

# find the best model run (highest average correlation, and both coefficients are larger than 0.6)

bestdf <- results %>% 
  filter(annual_min_cor > 0.6,
           annual_max_cor > 0.6) %>%  
  mutate(
    ave_cor = (annual_min_cor+annual_max_cor)/2
  ) %>% 
  arrange(-ave_cor)

return(list(resultsl, print(as.character(bestdf$simnames[1])), bestdf$ave_cor[1]))
}

```

```{r}
for(i in 1:length(groupingz)){
 test <- wrapper(data_F, groupingz)
}

```

1. the for loop wasn't working because groupings was created using c() instead of a list, so the numbers don't automatically loop through. To change this, use the notation 1:length() in the for loop 
2. some of the results came out as NA still, because they weren't meeting the requirements of min and max cor being > 0.6 

```{r}

# graph range of performance measures -- gotta find a way to access the list and then group by timestep
ggplot(test, aes(metric, value))+
  geom_boxplot()+
  labs(x='Performance Metric Correlated Variable',
       y='Pearson Correlation Coefficient',
       title = 'Model Performance: Correlation between Simulated and Observed Values')+
  facet_wrap(~groupingz, scales="free",
             labeller = as_labeller(metric_label))+
  theme_bw()+
  theme(axis.text.x = element_blank())
```



If you didn't want to use a for loop, here is another example 
```{r timesteps}

wrapper2 <- function(data_F, timestep){

group = data_F %>% dplyr::select(grouping=timestep) 
  
# apply the perform_metric function to our data
  
res = data_F %>% 
  select(-date, -month, -day, -year, -wy, -obs) %>%
  map_dfr(~perform_metric(m=.x, 
                          o=data_F$obs, 
                          # don't really need these other time steps, but am leaving them in because don't want to change the function
                          month = data_F$month, 
                          day = data_F$day,
                          year=data_F$year, 
                          wy=data_F$wy,
                          grouping=group))

# create an ID that tracks each model output
simnames = names(data_F %>% 
  select(-date, -month, -day,-year,-wy, -obs))

results = cbind.data.frame(simnames=simnames, res)

# Make results long format
resultsl = results %>% 
  gather(key="metric",value="value", -simnames) 

# find the best model run (highest average correlation, and both coefficients are larger than 0.6)

bestdf <- results %>% 
  filter(annual_min_cor > 0.6,
           annual_max_cor > 0.6) %>%  
  mutate(
    ave_cor = (annual_min_cor+annual_max_cor)/2
  ) %>% 
  arrange(-ave_cor)

return(list(df_rez=resultsl, bestsim=as.character(bestdf$simnames[1]), bestsim_cor=bestdf$ave_cor[1]))
}

timestep <- c('date', 'month', 'day', 'year', 'wy')
tmp <- timestep %>% map(.f=wrapper2, data_F=msage)
bestsim_res = tmp %>% map_dfr(`[`,c("bestsim","bestsim_cor")) %>% 
  mutate(timestep=timestep)
bestsim_res


boxplotable <- tmp %>% map_dfr(`[`,c("df_rez")) %>% 
  mutate(timestep = c(rep('date', times = 202), rep('month', times = 202), rep('day', times = 202), rep('year', times = 202), rep('wy', times = 202)))

```

```{r}

timestep_label <-timestep

ggplot()+
  geom_boxplot(data = boxplotable, aes(df_rez$metric, df_rez$value, group = df_rez$metric, color = df_rez$metric))+
  labs(x='Performance Metric Correlated Variable',
       y='Pearson Correlation Coefficient',
       title = 'Model Performance: Correlation between Simulated and Observed Values')+
  facet_wrap(~timestep, scales="free"
             )+
  theme_bw()+
  theme(axis.text.x = element_blank())

```


still getting NAs for month and day because the annual_min_cor does not go above 0.6, but this could be easily adjusted in the wrapper function to either change the threshold or use different weights to select the 'best' simulation 